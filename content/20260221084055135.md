+++
title = "El asistente personal con IA, Moltbot"
slug = "20260221084055135"
date = "2026-02-21T08:40:58.466478+01:00"
[taxonomies]
autor = ["Víctor Manuel Jáquez Leal"]
tema = ["articulos"]
+++

Cada mañana leo con asombro y horror noticias sobre el desarrollo y uso de la IA
generativa. Uno de los proyectos que más controversia ha motivado,
intensificando ambas emociones en mí, es [Moltbot](https://moltbot.org/), antes
llamado OpenClaw o Clawdbot. [Su documentación](https://docs.openclaw.ai/) lo
describe así:

> OpenClaw es una pasarela auto-hospedada que conecta tus aplicaciones de
> mensajería instantánea favoritas (WhatsApp, Telegram, Discord, iMessage y más)
> con agentes de programación con IA, como Pi. Ejecutas un único proceso
> pasarela en tu propio ordenador (o servidor), y este se convierte en el puente
> entre tus aplicaciones de mensajería y un asistente con IA siempre disponible.
>
> ¿Para quién es? Para desarrolladores y usuarios avanzados que quieren un
> asistente personal con IA al que puedan enviar mensajes desde cualquier lugar,
> sin renunciar al control de sus datos, ni depender de un servicio alojado
> externamente.

{% mermaid() %}
flowchart LR
  A["Chat apps + plugins"] --> B["Gateway"]
  B --> C["Pi agent"]
  B --> D["CLI"]
  B --> E["Web Control UI"]
  B --> F["macOS app"]
  B --> G["iOS and Android nodes"]
{% end %}

Por lo tanto, Moltbot es un **asistente personal con IA**: una aplicación que
utiliza inteligencia artificial para interactuar en lenguaje natural, yendo más
allá de comandos simples (como Siri o Alexa). Integra agentes con IA y utiliza
el contexto del usuario (como datos personales, interacciones previas,
ubicación, conocimiento organizacional, etc.) para ofrecer soporte
personalizado.

Podemos definirlo como un **bot personal de mensajería instantánea**, cuya
función es servir de interfaz para uno o varios agentes con IA que operan en
contextos definidos por el usuario.

Lo **personal** queda claro: el usuario instala y configura su propio bot en
hardware bajo su control, no es un servicio externo por suscripción.

## El asombro

El concepto clave es **agente con IA**. Moltbot utiliza por defecto una versión
modificada de
[Pi](https://github.com/badlogic/pi-mono/tree/main/packages/coding-agent).

Los agentes de IA representan un paso evolutivo en el uso de IA generativa:

- Los **chats** (como ChatGPT) son interfaces conversacionales con grandes
  modelos de lenguaje (LLM), pero limitados a su entrenamiento inicial, por lo
  que son monolíticos y estáticos.
- Se pueden extender con **herramientas** (*tools*) que les permiten acceder a
  fuentes externas (bases de datos, web, APIs) para enriquecer el contexto.
- Los **agentes** van más allá: tienen autonomía para descomponer tareas
  complejas, crear un plan, usar herramientas y ejecutarlas. Es decir, razonan
  el mundo y actúan sobre él.

Un ejemplo ilustrativo de cómo operaría un agente con IA:

<!-- pyml disable-next-line no-inline-html-->
<article>

Quiero saber cuánto bloqueador solar necesito para unas vacaciones en Puerto
Escondido.

El agente delinea el siguiente plan:

1. Consulta la base de datos de mi trabajo para saber las fechas de mis
   vacaciones.
2. Busca el pronóstico del tiempo en ese período para Puerto Escondido.
3. Busca recomendaciones de uso de bloqueador según las condiciones.
4. Calcula la cantidad necesaria.

Ejecuta cada subtarea con las herramientas disponibles y devuelve una respuesta.

<!-- pyml disable-next-line no-inline-html-->
</article>

## El horror

La gente se ha vuelto loca usando Moltbot volcando todo tipo de herramientas
para que el asistente opere sobre el mundo real, siguiendo la propensión humana
de sobrepasar todos los límites, sin considerar los problemas que pueden
ocasionar.

- [Prompt injection](https://en.wikipedia.org/wiki/Prompt_injection). Una de las
  grandes críticas a la IA generativa es que instrucciones y datos están
  revueltos. Entonces, un agente usando una herramienta para acceder a
  datos y éstos pueden contener instrucciones que ejecutaría el agente,
  provocando, por ejemplo, la divulgación de información privada de su usuario.
- [Moltbook](https://www.moltbook.com/) es un foro y red social exclusivamente
  para agentes con IA similar a Reddit, donde bots interactúan entre sí,
  publican contenido y comentan en sub-foros llamados "Submolts".
- Casos concretos:
  - Un usuario hizo que su bot analizara el código de varios proyectos de
    software libre de índole científica; si encontraba mejoras las propusiera y
    que blogueara sus resultados. El bot envió un [merge
    request](https://github.com/matplotlib/matplotlib/pull/31132) a Matplotlib,
    sin embargo era una alucinación que el mantenedor cerró de inmediato. Luego
    el bot escribió un blog sobre su experiencia, [acusando al mantenedor de
    prejuicio e
    hipocresía](https://crabby-rathbun.github.io/mjrathbun-website/blog/posts/2026-02-11-gatekeeping-in-open-source-the-scott-shambaugh-story.html).
  - Se han propalado en redes sociales experiencias de usuarios que dan a Molbot
    acceso a sus sesiones de Amazon, y el bot gasta miles de dólares en
    artículos innecesarios.
  - Otros, más osados, ha instruido a sus bots que inviertan en la bolsa, o
    apuesten en [Polymarket](https://polymarket.com/), al libre albedrío del
    agente, perdiendo dinero la más de las veces.

## Conclusión

Yo no voy a usar Moltbot, al menos a corto plazo. Y aunque utilizo agentes con
IA para programar (como Aider, del que ya hablé), todo esto me hace pensar que
debo usarlos dentro *sandboxes*, con permisos de ejecución mínimos y explícitos,
cuyas fuentes de información también estén controladas.
